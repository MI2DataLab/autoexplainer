{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import quantus\n",
    "from autoexplainer.utils import fix_relus_in_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Insert your stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### This is Resnet example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model to CPU/GPU device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Loading model to CPU/GPU device: {device}\")\n",
    "model = torch.load(f'../models/resnet_18.pth', map_location=device)\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((256, 256)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(\"../data/test\", transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Batch to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_batch, y_batch = iter(data_loader).next()\n",
    "predicted_labels = model(x_batch).argmax(axis=1)\n",
    "x_batch_np, y_batch_np = x_batch.cpu().numpy(), y_batch.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = fix_relus_in_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "https://captum.ai/tutorials/Image_and_Text_Classification_LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pawel/lazy-explain/.venv/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/pawel/lazy-explain/.venv/lib/python3.9/site-packages/captum/attr/_core/lime.py:664: UserWarning: Minimum element in feature mask is not 0, shifting indices to start at 0.\n",
      "  warnings.warn(\n",
      "Lime attribution: 100%|██████████| 25/25 [00:02<00:00,  8.45it/s]\n",
      "/Users/pawel/lazy-explain/.venv/lib/python3.9/site-packages/captum/attr/_core/lime.py:664: UserWarning: Minimum element in feature mask is not 0, shifting indices to start at 0.\n",
      "  warnings.warn(\n",
      "Lime attribution: 100%|██████████| 25/25 [00:02<00:00,  9.99it/s]\n",
      "/Users/pawel/lazy-explain/src/lazy_explain/explanations/custom.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  predictions = model(torch.tensor(inputs)).argmax(dim=1)\n",
      "/Users/pawel/lazy-explain/.venv/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "a_batch_gradients = quantus.explain(model, x_batch, y_batch, method=\"IntegratedGradients\", normalise=True)\n",
    "a_batch_saliency = quantus.explain(model, x_batch, y_batch, method=\"Saliency\", normalise=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnings and information:\n",
      " (1) The Faithfulness Estimate metric is likely to be sensitive to the choice of baseline value 'perturb_baseline' and similarity function 'similarity_func'. \n",
      " (2) If attributions are normalised or their absolute values are taken it may destroy or skew information in the explanation and as a result, affect the overall evaluation outcome.\n",
      " (3) Make sure to validate the choices for hyperparameters of the metric (by calling .get_params of the metric instance).\n",
      " (4) For further information, see original publication: Alvarez-Melis, David, and Tommi S. Jaakkola. 'Towards robust interpretability with self-explaining neural networks.' arXiv preprint arXiv:1806.07538 (2018).\n",
      " (5) To disable these warnings set 'disable_warnings' = True when initialising the metric.\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "metric = quantus.FaithfulnessEstimate(**{\n",
    "    \"perturb_func\": quantus.baseline_replacement_by_indices,\n",
    "    \"similarity_func\": quantus.correlation_pearson,\n",
    "    \"features_in_step\": 256,  \n",
    "    \"perturb_baseline\": \"mean\",  \n",
    "    \"pixels_in_step\": 28,\n",
    "})\n",
    "\n",
    "faithfulness_grad = metric(model=model, \n",
    "   x_batch=x_batch_np, \n",
    "   y_batch=y_batch_np,\n",
    "   a_batch=a_batch_gradients,\n",
    "   **{\"device\": device})\n",
    "\n",
    "faithfulness_saliency = metric(model=model, \n",
    "   x_batch=x_batch_np, \n",
    "   y_batch=y_batch_np,\n",
    "   a_batch=a_batch_saliency,\n",
    "   **{\"device\": device})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "irof = quantus.IterativeRemovalOfFeatures(**{\n",
    "    \"segmentation_method\": \"slic\",\n",
    "    \"perturb_baseline\": \"mean\",\n",
    "    \"perturb_func\": quantus.baseline_replacement_by_indices,\n",
    "    \"return_aggregate\": False,\n",
    "})\n",
    "\n",
    "irof_grad = irof(model=model,\n",
    "   x_batch=x_batch_np,\n",
    "   y_batch=y_batch_np,\n",
    "   a_batch=None,\n",
    "   **{\"explain_func\": quantus.explain, \"method\": \"IntegratedGradients\", \"device\": device})\n",
    "irof_saliency = irof(model=model,\n",
    "   x_batch=x_batch_np,\n",
    "   y_batch=y_batch_np,\n",
    "   a_batch=None,\n",
    "   **{\"explain_func\": quantus.explain, \"method\": \"Saliency\", \"device\": device})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lazy-explain-5JOxoICw-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fbe2b4cf964e4e47aa73b53fde8e72d6f5d412075b3dce524dd1bdafc0972c79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}